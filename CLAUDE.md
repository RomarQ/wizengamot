# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Development Commands

```bash
# Install dependencies (from project root)
uv sync                          # Backend Python dependencies
cd frontend && npm install       # Frontend JS dependencies

# Run the application
./start.sh                       # Start both backend and frontend
# OR manually:
uv run python -m backend.main    # Backend on port 8001
cd frontend && npm run dev       # Frontend on port 5173

# Frontend commands
cd frontend && npm run build     # Production build
cd frontend && npm run lint      # ESLint
```

## Project Overview

LLM Council is a 3-stage deliberation system where multiple LLMs collaboratively answer user questions via OpenRouter. The key innovation is anonymized peer review in Stage 2, preventing models from playing favorites.

## Architecture

### Backend Structure (`backend/`)

**`config.py`**
- Contains `COUNCIL_MODELS` (list of OpenRouter model identifiers)
- Contains `CHAIRMAN_MODEL` (model that synthesizes final answer)
- Uses environment variable `OPENROUTER_API_KEY` from `.env`
- Backend runs on **port 8001** (NOT 8000 - user had another app on 8000)

**`openrouter.py`**
- `query_model()`: Single async model query
- `query_models_parallel()`: Parallel queries using `asyncio.gather()`
- Returns dict with 'content' and optional 'reasoning_details'
- Graceful degradation: returns None on failure, continues with successful responses

**`council.py`** - The Core Logic
- `stage1_collect_responses()`: Parallel queries to all council models
- `stage2_collect_rankings()`:
  - Anonymizes responses as "Response A, B, C, etc."
  - Creates `label_to_model` mapping for de-anonymization
  - Prompts models to evaluate and rank (with strict format requirements)
  - Returns tuple: (rankings_list, label_to_model_dict)
  - Each ranking includes both raw text and `parsed_ranking` list
- `stage3_synthesize_final()`: Chairman synthesizes from all responses + rankings
- `parse_ranking_from_text()`: Extracts "FINAL RANKING:" section, handles both numbered lists and plain format
- `calculate_aggregate_rankings()`: Computes average rank position across all peer evaluations

**`storage.py`**
- JSON-based conversation storage in `data/conversations/`
- Each conversation: `{id, created_at, messages[]}`
- Assistant messages contain: `{role, stage1, stage2, stage3}`
- Note: metadata (label_to_model, aggregate_rankings) is NOT persisted to storage, only returned via API

**`main.py`**
- FastAPI app with CORS enabled for localhost:5173 and localhost:3000
- POST `/api/conversations/{id}/message` returns metadata in addition to stages
- Metadata includes: label_to_model mapping and aggregate_rankings

### Frontend Structure (`frontend/src/`)

**`App.jsx`**
- Main orchestration: manages conversations list and current conversation
- Handles message sending and metadata storage
- Important: metadata is stored in the UI state for display but not persisted to backend JSON

**`components/ChatInterface.jsx`**
- Multiline textarea (3 rows, resizable)
- Enter to send, Shift+Enter for new line
- User messages wrapped in markdown-content class for padding

**`components/Stage1.jsx`**
- Tab view of individual model responses
- Uses ResponseWithComments for inline highlights and popups

**`components/Stage2.jsx`**
- **Critical Feature**: Tab view showing RAW evaluation text from each model
- De-anonymization happens CLIENT-SIDE for display (models receive anonymous labels)
- Shows "Extracted Ranking" below each evaluation so users can validate parsing
- Aggregate rankings shown with average position and vote count
- Explanatory text clarifies that boldface model names are for readability only
- Uses ResponseWithComments for inline highlights and popups

**`components/Stage3.jsx`**
- Final synthesized answer from chairman
- Green-tinted background (#f0fff0) to highlight conclusion
- Uses ResponseWithComments for inline highlights and popups

**Comment System Components**
- **`ResponseWithComments.jsx`**: Wrapper that applies inline highlights and manages hover popups
- **`HighlightPopup.jsx`**: Responsive popup that appears next to highlighted text, shows comment content and delete button
- **`CommentModal.jsx`**: Modal for adding new comments to selected text
- **`CommitModal.jsx`**: Enhanced modal showing full context (highlighted text + comments + metadata) when starting follow-up threads
- **`ThreadView.jsx`**: Component for continuing follow-up conversations with individual models
- **`SelectionHandler.js`**: Utility for text selection, highlighting, and popup positioning

**Styling (`*.css`)**
- Light mode theme (not dark mode)
- Primary color: #4a90e2 (blue)
- Global markdown styling in `index.css` with `.markdown-content` class
- 12px padding on all markdown content to prevent cluttered appearance

## Key Design Decisions

### Stage 2 Prompt Format
The Stage 2 prompt is very specific to ensure parseable output:
```
1. Evaluate each response individually first
2. Provide "FINAL RANKING:" header
3. Numbered list format: "1. Response C", "2. Response A", etc.
4. No additional text after ranking section
```

This strict format allows reliable parsing while still getting thoughtful evaluations.

### De-anonymization Strategy
- Models receive: "Response A", "Response B", etc.
- Backend creates mapping: `{"Response A": "openai/gpt-5.1", ...}`
- Frontend displays model names in **bold** for readability
- Users see explanation that original evaluation used anonymous labels
- This prevents bias while maintaining transparency

### Error Handling Philosophy
- Continue with successful responses if some models fail (graceful degradation)
- Never fail the entire request due to single model failure
- Log errors but don't expose to user unless all models fail

### UI/UX Transparency
- All raw outputs are inspectable via tabs
- Parsed rankings shown below raw text for validation
- Users can verify system's interpretation of model outputs
- This builds trust and allows debugging of edge cases

## Important Implementation Details

### Relative Imports
All backend modules use relative imports (e.g., `from .config import ...`) not absolute imports. This is critical for Python's module system to work correctly when running as `python -m backend.main`.

### Port Configuration
- Backend: 8001 (changed from 8000 to avoid conflict)
- Frontend: 5173 (Vite default)
- Update both `backend/main.py` and `frontend/src/api.js` if changing

### Markdown Rendering
All ReactMarkdown components must be wrapped in `<div className="markdown-content">` for proper spacing. This class is defined globally in `index.css`.

### Model Configuration
Models are hardcoded in `backend/config.py`. Chairman can be same or different from council members. The current default is Gemini as chairman per user preference.

## Common Gotchas

1. **Module Import Errors**: Always run backend as `python -m backend.main` from project root, not from backend directory
2. **CORS Issues**: Frontend must match allowed origins in `main.py` CORS middleware
3. **Ranking Parse Failures**: If models don't follow format, fallback regex extracts any "Response X" patterns in order
4. **Missing Metadata**: Metadata is ephemeral (not persisted), only available in API responses

## Future Enhancement Ideas

- Configurable council/chairman via UI instead of config file
- Streaming responses instead of batch loading
- Export conversations to markdown/PDF
- Model performance analytics over time
- Custom ranking criteria (not just accuracy/insight)
- Support for reasoning models (o1, etc.) with special handling

## Data Flow Summary

```
User Query
    ↓
Stage 1: Parallel queries → [individual responses]
    ↓
Stage 2: Anonymize → Parallel ranking queries → [evaluations + parsed rankings]
    ↓
Aggregate Rankings Calculation → [sorted by avg position]
    ↓
Stage 3: Chairman synthesis with full context
    ↓
Return: {stage1, stage2, stage3, metadata}
    ↓
Frontend: Display with tabs + validation UI
```

The entire flow is async/parallel where possible to minimize latency.

## Comment & Annotation System

### Overview
Users can highlight text in any stage response, add comments, and use those comments to start follow-up threads with individual council members. Comments are stored locally and displayed as inline highlights with hover popups.

### Key Features

**1. Inline Highlighting**
- Text selection creates persistent yellow highlights in the response
- Highlights use `<mark>` elements with `data-comment-id` attributes
- Hover over highlights shows responsive popup with comment details
- Active highlights get visual feedback (darker background)

**2. Responsive Hover Popups**
- Position intelligently (right, left, below based on viewport)
- Show comment content, stage info, timestamp
- Delete button for removing comments
- Smooth fade-in animation
- Smart positioning avoids viewport edges

**3. Comment Modal**
- Triggered by text selection
- Shows selected text, stage, and model context
- Keyboard shortcuts: Ctrl+Enter to save, Esc to cancel
- Creates comment with unique ID and timestamp

**4. Enhanced Commit Modal**
- Shows ALL comment context before starting follow-up
- Each comment displayed as card with:
  - Comment number badge
  - Stage and model badges
  - Highlighted text excerpt
  - Full comment content
  - Context inclusion note
- Allows selecting target model for follow-up
- User provides follow-up question

**5. Thread View**
- Direct conversation with selected model
- Comment context automatically included in first message
- Back-and-forth interaction maintained
- Thread history persisted

### Technical Implementation

**SelectionHandler.js**
- `getSelection()`: Captures text selection with position data
- `createHighlight()`: Creates `<mark>` elements for persistent highlights
- `removeHighlight()`: Cleanly removes highlights by comment ID
- `calculatePopupPosition()`: Smart positioning algorithm for popups
- `_getTextNodes()`: Traverses DOM to find text nodes for highlighting

**ResponseWithComments.jsx**
- Manages highlight lifecycle (creation, event listeners, cleanup)
- Handles hover and click interactions
- Shows/hides HighlightPopup based on interaction
- Coordinates with SelectionHandler for DOM manipulation

**HighlightPopup.jsx**
- Positioned absolutely based on highlight rect
- Arrow pointing to highlighted text
- Delete functionality triggers cascade: popup close → highlight remove → storage update

**CommitModal.jsx**
- Enhanced to show rich context cards
- Each card includes all metadata (stage, model, selection, comment)
- Visual hierarchy with badges and structured layout
- Clear indication that context will be included

### Storage
Comments stored in App.jsx state as array of objects:
```javascript
{
  id: string,           // Unique identifier
  selection: string,    // Highlighted text
  content: string,      // User's comment
  stage: number,        // 1, 2, or 3
  model: string,        // Model identifier
  message_index: number,// Which message in conversation
  created_at: string    // ISO timestamp
}
```

### Delete Workflow
1. User clicks delete in popup or annotation
2. Component calls `onDeleteComment(commentId)`
3. App.jsx removes from state
4. SelectionHandler.removeHighlight() cleans DOM
5. UI updates to remove both highlight and popup

### Styling
- Yellow highlight: `#fff3cd` background, `#ffc107` border
- Hover state: `#ffe69c` background
- Active state: `#ff9800` border
- Popup: white with subtle shadow, 300px max width
- Global styles in `index.css` for consistency

### Future Enhancements
- Multiple comments per selection (comment threads)
- Comment replies/discussions
- Export comments with highlighted context
- Search/filter comments
- Comment analytics (most commented sections)
- Shareable comment links
